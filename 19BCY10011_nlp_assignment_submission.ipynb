{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "19BCY10011_nlp_assignment_submission",
      "provenance": [],
      "authorship_tag": "ABX9TyPCPoObTxt4fxGg/1jrSo7O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smartinternz02/SI-GuidedProject-9837-1648544575/blob/main/19BCY10011_nlp_assignment_submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBrr-5YhglGC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "dataset = pd.read_csv(\"E:/Training/May4th-rsip2020/Natural Language Processing/Restaurant_Reviews.tsv\",delimiter = \"\\t\")\n",
        "import re # used to replace special characters\n",
        "import nltk #natural language tool kit - all the necessary libaries for \n",
        "nltk.download(\"stopwords\") # nltk corpus - data is stored\n",
        "from nltk.corpus import stopwords # detect stopwords\n",
        "from nltk.stem.porter import PorterStemmer # stem your word \n",
        "ps = PorterStemmer()\n",
        "\n",
        "data = []\n",
        "\n",
        "df = pd.DataFrame([[\"a\"],[\"b\"],[\"c\"]],columns = [\"hey\"])\n",
        "print(df)\n",
        "print(df[\"hey\"][0])\n",
        "for i in range(0,1000):\n",
        "    review = dataset[\"Review\"][i]\n",
        "    review = re.sub('[^a-zA-Z]', ' ',review)\n",
        "    review = review.lower()\n",
        "    review = review.split() #[wow, loved , this, place]\n",
        "    \n",
        "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "    review = ' '.join(review)\n",
        "    data.append(review)\n",
        "    \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features = 2000)\n",
        "x = cv.fit_transform(data).toarray()\n",
        "y = dataset.iloc[:,1:2].values\n",
        "b = [\"wow love place\",\"awesome place\" , \" wow love  ambience\"]\n",
        "\n",
        "ct = CountVectorizer(max_features = 5)\n",
        "\n",
        "c = ct.fit_transform(b).toarray()\n",
        "\n",
        "\"\"\"ambience awesome love place wow\n",
        "0         0       1    1     1\n",
        "0         1       0    1     0\n",
        "1         0       1    0      1\"\"\"\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2, random_state = 0)\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "model =  Sequential()\n",
        "model.add(Dense(units = 1565,kernel_initializer = \"random_uniform\",activation= \"relu\"))\n",
        "model.add(Dense(units = 3000,kernel_initializer = \"random_uniform\",activation= \"relu\"))\n",
        "model.add(Dense(units = 3000,kernel_initializer = \"random_uniform\",activation= \"relu\"))\n",
        "model.add(Dense(units = 1,kernel_initializer = \"random_uniform\",activation= \"sigmoid\"))\n",
        "model.compile(optimizer = \"rmsprop\",loss = \"binary_crossentropy\",metrics = [\"accuracy\"])\n",
        "model.fit(x_train,y_train, epochs = 5)\n",
        "a = [i*i for i in range(12) if(i%2==0)]\n",
        "\n",
        "pred = model.predict(x_test)\n",
        "pred = pred>0.5\n",
        "\n",
        "yp = model.predict(cv.transform([\"bad\"]))\n",
        "\n",
        "text = \"the worst food i have evr tasetd.... crust is very bad\"\n",
        "\n",
        "text = re.sub('[^a-zA-Z]', ' ',text)\n",
        "text = text.lower()\n",
        "text = text.split() #[wow, loved , this, place]\n",
        "    \n",
        "text = [ps.stem(word) for word in text if not word in set(stopwords.words('english'))]\n",
        "text = ' '.join(text)\n",
        "yp = model.predict(cv.transform([text]))\n",
        "yp>0.5\n"
      ]
    }
  ]
}